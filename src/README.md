# Parallel Graph Traversal

Ãn acest proiect am implementat un **Thread Pool** generic Ã®n C
È™i l-am folosit pentru a parcurge un graf Ã®n paralel.

Structura este inspiratÄƒ de listele dublu-Ã®nlanÈ›uite din **kernel-ul Linux** 
È™i de clasica problemÄƒ **producÄƒtor-consumator**.

Implementarea este modularÄƒ:
- `os_list` => listÄƒ dublu-Ã®nlanÈ›uitÄƒ genericÄƒ
- `os_threadpool` => infrastructura de paralelizare
- `os_graph` => structura È™i iniÈ›ializarea grafului
- `parallel` => algoritmul de parcurgere paralelÄƒ

## Thread Pool

Acest **design pattern** presupune implementarea a douÄƒ componente principale:
- Un pool de task-uri de executat, reprezentat de o `coadÄƒ`
- Un grup de **workeri** (**thread**-uri)

```c
typedef struct os_threadpool {
	unsigned int num_threads;
	pthread_t *threads;

	/* Head of queue used to store tasks. */
	os_list_node_t head;

	/* Threadpool / queue synchronization data. */
	pthread_mutex_t queue_mtx;
	pthread_cond_t has_tasks;
	int stop_flag;            // 0 -> is running, 1 -> shutdown
} os_threadpool_t;
```

Ãn implementarea Thread Pool-ului meu, am folosit urmÄƒtoarele primitive de sincronizare:
- Un **mutex**:
    care protejeazÄƒ accesurile paralele asupra cozii
- O **variabilÄƒ condiÈ›ionalÄƒ** (`pthread_cond_t`):
    utilizatÄƒ pentru a bloca thread-urile atunci cÃ¢nd coada este goalÄƒ
    È™i pentru a le trezi atunci cÃ¢nd se insereazÄƒ noi taskuri.
    Practic, `enqueue_task` face `pthread_cond_signal` (trezeÈ™te un worker),
    iar `wait_for_completion` face `pthread_cond_broadcast` (trezeÈ™te toate thread-urile pentru **shutdown**).
- Un **flag** (`stop`):
    care marcheazÄƒ momentul Ã®n care Thread Pool-ul trebuie sÄƒ se opreascÄƒ (mecanism de **graceful shutdown**).
    CÃ¢nd `stop=1`, workerii nu mai aÈ™teaptÄƒ taskuri noi È™i ies din bucla principalÄƒ dupÄƒ ce coada se goleÈ™te.


Fluxul algoritmului:
  1. `enqueue_task` => insereazÄƒ un task Ã®n coadÄƒ È™i notificÄƒ un worker
  2. Worker-ul ruleazÄƒ `dequeue_task` => aÈ™teaptÄƒ dacÄƒ nu sunt taskuri
  3. DupÄƒ ce primeÈ™te un task, executÄƒ funcÈ›ia (`action`), apoi Ã®l elibereazÄƒ (`destroy_task`)
  4. `wait_for_completion` => seteazÄƒ `stop = 1`, notificÄƒ toÈ›i workerii È™i face `join`

## Graf

- Graf neorientat stocat ca **vector de noduri**, fiecare nod avÃ¢nd:
  - `info`: valoarea asociatÄƒ nodului
  - `neighbours`: vector cu indecÈ™ii vecinilor
- `visited`: vector de stÄƒri (`NOT_VISITED`, `PROCESSING`, `DONE`)

## Parcurgerea paralelÄƒ

- Se porneÈ™te de la nodul cu indexul `0`
- Pentru fiecare nod:
  1. Se marcheazÄƒ `PROCESSING` È™i se adaugÄƒ valoarea nodului la **sumÄƒ globalÄƒ**
  2. Se creeazÄƒ taskuri pentru vecinii **nevizitaÈ›i**
  3. La final, nodul devine `DONE`
- Accesul la `visited` È™i `sum` este protejat cu un **mutex global**



## ğŸ›¡ï¸ Sincronizare È™i memory management

**Thread safety**: accesul la `graph->visited` È™i `sum` este protejat cu `pthread_mutex_t graph_lock`

**Memory management**:
- Argumentele taskurilor (`graph_task_arg_t`) sunt **alocate dinamic pe heap**
- Eliberarea se face exclusiv prin `destroy_task` => evitÄƒ `double free`

<!-- 
## Observatii


De ce nu este o idee buna la `dequeue_task` sa pui lock pe coada
si sa returnezi direct `NULL` daca coada este vida?
 -->
